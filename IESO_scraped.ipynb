{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:16.307996Z",
     "start_time": "2021-07-19T18:52:15.732102Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html as lh\n",
    "import pandas as pd\n",
    "#pip install requests beautifulsoup\n",
    "#!pip install selenium\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "# datetime library\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import re\n",
    "import smtplib\n",
    "import imghdr\n",
    "import cgi\n",
    "import ssl\n",
    "import html\n",
    "import uuid\n",
    "import os\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text      import MIMEText\n",
    "from email.mime.image     import MIMEImage\n",
    "from email.header         import Header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Webscrapping data ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Selenium Tutorial ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:17.402218Z",
     "start_time": "2021-07-19T18:52:16.309651Z"
    }
   },
   "outputs": [],
   "source": [
    "# QUICK SELENIUM (webscraping robot) INSTALLATION GUIDE\n",
    "\n",
    "# Step 1: Download chromedriver and create and extract to file path\n",
    "# First need to download chromedriver (https://chromedriver.chromium.org/) to allow selenium to be used\n",
    "# Create folder C:\\Drivers\\Chrome and extract the downloaded chromedriver file to this location\n",
    "\n",
    "# select chromedriver path from directory \n",
    "driver =webdriver.Chrome(executable_path=\"C:\\Drivers\\Chrome\\chromedriver.exe\")\n",
    "\n",
    "\n",
    "# Step 2: Follow guide below to add to system environment, stop before Steps to run Selenium Tests on Chrome Browser\n",
    "# LINK: https://www.browserstack.com/guide/run-selenium-tests-using-selenium-chromedriver )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:17.418174Z",
     "start_time": "2021-07-19T18:52:17.406206Z"
    }
   },
   "outputs": [],
   "source": [
    "# FOLLOW GUIDE to learn how to find XPaths https://www.youtube.com/watch?v=b5pCd6-ZvQ0&t=317s&ab_channel=SDET-QAAutomationTechie "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Webscrapping IESO forecasted data and current yearly peaks ###\n",
    "https://www.ieso.ca/peaktracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:18.918165Z",
     "start_time": "2021-07-19T18:52:17.421166Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Direct driver to the website that will be scraped\n",
    "driver.get(\"https://www.ieso.ca/peaktracker\")\n",
    "# obtaining daily energy consumption info from IESO, based on IESO predictive algos\n",
    "# this is a really weird table format, the 2nd div corresponds to the column and the tr xpath tag counts up from 1 to 24, so leaving both blank \n",
    "# (no [1][3] beside them, find_elements will count them all)\n",
    "all_hours=len(driver.find_elements_by_xpath(\"//*[@id='demandForecast']/div[2]/div/table/tbody/tr/td[1]\"))\n",
    "all_values = len(driver.find_elements_by_xpath(\"//*[@id='demandForecast']/div[2]/div/table/tbody/tr/td[2]\"))\n",
    "\n",
    "# obtaining current year top 5 peak information\n",
    "rows_h=len(driver.find_elements_by_xpath(\"//*[@id='ieso-page-well']/div[7]/div/div[1]/div/div[3]/table/tbody/tr\"))\n",
    "cols_h= len(driver.find_elements_by_xpath(\"//*[@id='ieso-page-well']/div[7]/div/div[1]/div/div[3]/table/tbody/tr[1]/td\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:18.933126Z",
     "start_time": "2021-07-19T18:52:18.919162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total individual hours:\n",
      "24\n",
      "total individual value:\n",
      "24\n",
      "Historical Peak Rows:\n",
      "10\n",
      "Historical peak columns:\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# view number of rows and cols and compare with website to ensure correct number\n",
    "print(\"total individual hours:\")\n",
    "print(all_hours)\n",
    "\n",
    "print(\"total individual value:\")\n",
    "print(all_values)\n",
    "print(\"Historical Peak Rows:\")\n",
    "print(rows_h)\n",
    "print('Historical peak columns:')\n",
    "print(cols_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:18.948084Z",
     "start_time": "2021-07-19T18:52:18.936116Z"
    }
   },
   "outputs": [],
   "source": [
    "# create blank dataframe of series (1 column) of data scraped weekly forecast data, later transformed into table\n",
    "scraped_df = pd.DataFrame()\n",
    "# create blank dataframe of series (1 column) of data scraped historical peak data, later transformed into table\n",
    "scraped_df_h = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:20.149911Z",
     "start_time": "2021-07-19T18:52:18.950080Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating for loop for each row \n",
    "#Scraping data from forecast table and saving to df scraped_df\n",
    "\n",
    "for t in range (1,all_values+1):\n",
    "    hour=driver.find_element_by_xpath(\"//*[@id='demandForecast']/div[2]/div/table/tbody/tr[\"+str(t)+\"]/td[1]\").text\n",
    "    value=driver.find_element_by_xpath(\"//*[@id='demandForecast']/div[2]/div/table/tbody/tr[\"+str(t)+\"]/td[2]\").text\n",
    "    # appending to df...\n",
    "    scraped_df = scraped_df.append({'hour': hour, 'Maximum_Forecasted_Ontario_Demand_(MW)':value},ignore_index=True)\n",
    "    \n",
    "    \n",
    "#Scraping data from historical peaks table and saving to df scraped_df_h       \n",
    "for r in range (1,rows_h+1):\n",
    "    # Path for driver to take value from\n",
    "    Day=driver.find_element_by_xpath(\"//*[@id='ieso-page-well']/div[7]/div/div[1]/div/div[3]/table/tbody/tr[\"+str(r)+\"]/td[2]/span\").text\n",
    "    Hour=driver.find_element_by_xpath(\"//*[@id='ieso-page-well']/div[7]/div/div[1]/div/div[3]/table/tbody/tr[\"+str(r)+\"]/td[3]/span\").text\n",
    "    Ontario_Demand=driver.find_element_by_xpath(\"//*[@id='ieso-page-well']/div[7]/div/div[1]/div/div[3]/table/tbody/tr[\"+str(r)+\"]/td[4]/span\").text\n",
    "        \n",
    "    # appending to df...\n",
    "    scraped_df_h = scraped_df_h.append({'Day': Day,'Hour': Hour, 'Ontario_Demand_(MW)':Ontario_Demand},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Viewing dataframes (smart tables we made) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:20.165868Z",
     "start_time": "2021-07-19T18:52:20.150910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Maximum_Forecasted_Ontario_Demand_(MW) hour\n",
      "0                                  20,478   14\n",
      "1                                  20,764   15\n",
      "2                                  21,267   16\n",
      "3                                  21,717   17\n",
      "4                                  21,771   18\n",
      "5                                  21,576   19\n",
      "6                                  21,050   20\n",
      "7                                  20,485   21\n",
      "8                                  19,224   22\n",
      "9                                  17,652   23\n",
      "10                                 16,251   24\n",
      "11                                 15,143    1\n",
      "12                                 14,381    2\n",
      "13                                 13,904    3\n",
      "14                                 13,762    4\n",
      "15                                 14,426    5\n",
      "16                                 15,366    6\n",
      "17                                 16,383    7\n",
      "18                                 17,241    8\n",
      "19                                 17,988    9\n",
      "20                                 18,359   10\n",
      "21                                 18,958   11\n",
      "22                                 19,322   12\n",
      "23                                 19,557   13\n"
     ]
    }
   ],
   "source": [
    "# print table to check if forecast scrape was successful\n",
    "print(scraped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:20.180862Z",
     "start_time": "2021-07-19T18:52:20.167892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Day Hour Ontario_Demand_(MW)\n",
      "0  June 28, 2021   18              22,258\n",
      "1  June 29, 2021   12              21,711\n",
      "2  July 06, 2021   17              21,655\n",
      "3  July 14, 2021   17              21,368\n",
      "4  June 07, 2021   17              21,340\n",
      "5  June 09, 2021   17              21,157\n",
      "6  July 15, 2021   17              20,971\n",
      "7  July 05, 2021   17              20,952\n",
      "8  June 27, 2021   18              20,904\n",
      "9  July 13, 2021   17              20,748\n"
     ]
    }
   ],
   "source": [
    "# print table to check if historical peak scrape was successful\n",
    "print(scraped_df_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:20.196820Z",
     "start_time": "2021-07-19T18:52:20.181826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Maximum_Forecasted_Ontario_Demand_(MW)    object\n",
       "hour                                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to see if dtypes are as desired \n",
    "scraped_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:20.212745Z",
     "start_time": "2021-07-19T18:52:20.197783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Day                    object\n",
       "Hour                   object\n",
       "Ontario_Demand_(MW)    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to see if dtypes are as desired \n",
    "scraped_df_h.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:20.227725Z",
     "start_time": "2021-07-19T18:52:20.214739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "# checking position of hour in dataframe (row, column)\n",
    "print(scraped_df.iloc[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:20.243663Z",
     "start_time": "2021-07-19T18:52:20.228701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20,478'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking position of predicted energy consumption in dataframe (row, column)\n",
    "scraped_df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:20.275575Z",
     "start_time": "2021-07-19T18:52:20.245663Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# replacing all \",\" in order to be able to convert from object string to int\n",
    "\n",
    "for i in range (0,all_hours):\n",
    "    \n",
    "    scraped_df.iloc[i,0] = re.sub(r'\\,', ' ', scraped_df.iloc[i,0]) # remove \",\"\n",
    "    scraped_df.iloc[i,0] = re.sub(' +',' ',scraped_df.iloc[i,0]) # remove more than one space \n",
    "    scraped_df.iloc[i,0] = re.sub(r'\\s+','',scraped_df.iloc[i,0])\n",
    "\n",
    "for i in range (0,rows_h):\n",
    "    \n",
    "    scraped_df_h.iloc[i,2] = re.sub(r'\\,', ' ', scraped_df_h.iloc[i,2]) # remove \",\"\n",
    "    scraped_df_h.iloc[i,2] = re.sub(' +',' ',scraped_df_h.iloc[i,2]) # remove more than one space \n",
    "    scraped_df_h.iloc[i,2] = re.sub(r'\\s+','',scraped_df_h.iloc[i,2])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:20.291533Z",
     "start_time": "2021-07-19T18:52:20.276573Z"
    }
   },
   "outputs": [],
   "source": [
    "## above code isnt working so added extra conversion, for some reason this one works on Object type    \n",
    "scraped_df['Maximum_Forecasted_Ontario_Demand_(MW)']=scraped_df['Maximum_Forecasted_Ontario_Demand_(MW)'].astype(int)\n",
    "\n",
    "scraped_df_h['Ontario_Demand_(MW)']=scraped_df_h['Ontario_Demand_(MW)'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:20.307490Z",
     "start_time": "2021-07-19T18:52:20.292530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21340\n"
     ]
    }
   ],
   "source": [
    "# check to see if commas were removed\n",
    "print(scraped_df_h.iloc[4,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Analysis ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Peak hour of the day and 5th highest yearly peak ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:20.323447Z",
     "start_time": "2021-07-19T18:52:20.308489Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "## obtaining the max forecasted energy use value for the day (which the IESO would base the peak hour on)\n",
    "\n",
    "df=scraped_df[scraped_df['Maximum_Forecasted_Ontario_Demand_(MW)']==scraped_df['Maximum_Forecasted_Ontario_Demand_(MW)'].max()]\n",
    "df=df.reset_index(drop=True)\n",
    "daily_peak = df.iloc[0,0]\n",
    "\n",
    "## obtaining the value for the 5th highest peak of the year , used later to determine if the forecasted peak is of concern\n",
    "fifth_peak = scraped_df_h.iloc[4,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:20.338408Z",
     "start_time": "2021-07-19T18:52:20.324446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21771"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_peak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Datetime formatting ###\n",
    "Formatting peak hour into proper datetime format ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:20.354400Z",
     "start_time": "2021-07-19T18:52:20.339405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'07/19/2021 17:00:00'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get current date from date time in format \n",
    "today = pd.to_datetime(\"today\").strftime(\"%m/%d/%Y\")\n",
    "\n",
    "# formatting for datetime (need to match to proper format of other python file used later) \n",
    "df['hour']=df['hour'].astype(int)\n",
    "# hour ending -> hour starting\n",
    "hour_converter = df.iloc[0,1]-1\n",
    "datetime_converter = \":00:00\"\n",
    "blanks = \" \"\n",
    "        \n",
    "# creating peak_date variable for textfile\n",
    "potential_peak_date = today+blanks+str(hour_converter)+datetime_converter\n",
    "potential_peak_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Risk Classfication ###\n",
    "Classifying image to use based on severity of daily peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:20.370323Z",
     "start_time": "2021-07-19T18:52:20.355362Z"
    }
   },
   "outputs": [],
   "source": [
    "# classifying risk level based on the severity of the daily peak\n",
    "# there is an assosciated image with every bin that will be embedded into the email later in code\n",
    "risk_level = 'Default'\n",
    "if daily_peak < 20000:\n",
    "    risk_level='Very Low'\n",
    "    path = u'C:/Users/ty11.LAPTOP-TSRNCK40/OneDrive/Documents/Rankin Co/0.3x/20000.png'\n",
    "if daily_peak >= 20000 and daily_peak < 20500:\n",
    "    risk_level='Moderate'\n",
    "    path = u'C:/Users/ty11.LAPTOP-TSRNCK40/OneDrive/Documents/Rankin Co/0.3x/20500.png' \n",
    "if daily_peak >= 20500 and daily_peak < 21000:\n",
    "    risk_level='Moderate to High'\n",
    "    path = u'C:/Users/ty11.LAPTOP-TSRNCK40/OneDrive/Documents/Rankin Co/0.3x/21000.png'\n",
    "if daily_peak >= 21000 and daily_peak < 21750:\n",
    "    risk_level='High'\n",
    "    path = u'C:/Users/ty11.LAPTOP-TSRNCK40/OneDrive/Documents/Rankin Co/0.3x/21500.png'\n",
    "if daily_peak >= 21750:\n",
    "    risk_level='Extremely High'\n",
    "    path = u'C:/Users/ty11.LAPTOP-TSRNCK40/OneDrive/Documents/Rankin Co/0.3x/22000.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:20.386279Z",
     "start_time": "2021-07-19T18:52:20.372317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extremely High'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view risk level\n",
    "risk_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Alert Email ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Email Construction ###\n",
    "Construct message for email, will only be sent if conditions are met:\n",
    "\n",
    "Condition 1: Daily peak > 5th highest peak of this year\n",
    "\n",
    "Condition 2: Daily peak > 20500MW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:58.697005Z",
     "start_time": "2021-07-19T18:52:58.681046Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating email body and subject line and storing in string variable\n",
    "message=\"\\n\\n There is {} risk of top 5 peak energy hour anticipated today,  {}, between {} and {} EST, with a forecasted Ontario demand of: {} MW. \\n\\n Have a great day!\".format(risk_level,today,str(hour_converter)+datetime_converter,str(hour_converter+1)+datetime_converter,daily_peak)\n",
    "subject_line = 'Peak Alert System: ' + risk_level + ' risk of peak from ' + str(hour_converter) + datetime_converter + ' to ' +str(hour_converter+1) + datetime_converter + ' EST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Embedding  image in an email ###\n",
    "Fucking hard:\n",
    "https://stackoverflow.com/questions/19171742/send-e-mail-to-gmail-with-inline-image-using-python\n",
    "https://code.activestate.com/recipes/473810-send-an-html-email-with-embedded-image-and-plain-t/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:20.417198Z",
     "start_time": "2021-07-19T18:52:20.402239Z"
    }
   },
   "outputs": [],
   "source": [
    "## follow those guides and best of luck if this breaks , worst case\n",
    "## remove images and just send message variable made above\n",
    "img = dict(title=u'Picture report…', path=path, cid=str(uuid.uuid4()))\n",
    "\n",
    "\n",
    "msg = MIMEMultipart('related')\n",
    "msg['Subject'] = Header(u'{}'.format(subject_line), 'utf-8')\n",
    "msg['From'] = \"rankin.alerts@gmail.com\"\n",
    "msg['To'] = \"rankin.alerts@gmail.com\"\n",
    "msg_alternative = MIMEMultipart('alternative')\n",
    "msg.attach(msg_alternative)\n",
    "\n",
    "\n",
    "msg_text = MIMEText(u'[image: {title}]'.format(**img), 'plain', 'utf-8')\n",
    "\n",
    "msg_alternative.attach(msg_text)\n",
    "\n",
    "msg_html = MIMEText(u' {} <div dir=\"ltr\">'\n",
    "                     '<img src=\"cid:{cid}\" alt=\"{alt}\"><br></div>'\n",
    "                    .format(message, alt=html.escape(img['title'], quote=True), **img),\n",
    "                    'html', 'utf-8')\n",
    "\n",
    "msg_alternative.attach(msg_html)\n",
    "\n",
    "with open(img['path'], 'rb') as file:\n",
    "    msg_image = MIMEImage(file.read(), name=os.path.basename(img['path']))\n",
    "    msg.attach(msg_image)\n",
    "msg_image.add_header('Content-ID', '<{}>'.format(img['cid']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Sending email  ###\n",
    "Check to see if conditions are met, if so send the alert, if not the program ends until the following day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:52:21.836807Z",
     "start_time": "2021-07-19T18:52:20.418195Z"
    }
   },
   "outputs": [],
   "source": [
    "## open text file to append string to\n",
    "file_object = open('C:/Users/ty11.LAPTOP-TSRNCK40/OneDrive/Documents/predicted_peaks.txt', 'a')\n",
    "\n",
    "# check to see conditions are met to warrant potential peak\n",
    "if daily_peak > 20500 and daily_peak>fifth_peak:\n",
    "        #*********************\n",
    "        #creating potential_peak variable to store peaks and transfer to text file\n",
    "    potential_peak= daily_peak\n",
    "    potential_peak_date = potential_peak_date\n",
    "    \n",
    "#############################SEND EMAIL##################################################\n",
    "    Sender_Email = \"rankin.alerts@gmail.com\"\n",
    "    \n",
    "    Password = '@Penguins12'\n",
    "\n",
    "    with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:\n",
    "        smtp.login(Sender_Email, Password)              \n",
    "        smtp.sendmail(msg['From'],msg['To'],msg.as_string())\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "        \n",
    "# Append potential peaks date and value at the end of file (1 entry per line)\n",
    "    file_object.write(str(potential_peak_date))\n",
    "    file_object.write(',')\n",
    "    file_object.write(str(potential_peak))\n",
    "    file_object.write('\\n')  \n",
    "    \n",
    "else:\n",
    "    print(\"No peaks today\")\n",
    "        \n",
    "# Close the textfile\n",
    "file_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
